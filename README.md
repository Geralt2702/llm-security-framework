# README.md - Dokumentacja frameworka

```markdown
# ğŸ” LLM Security Test Framework

Automatyczne, komprehensywne testowanie podatnoÅ›ci lokalnych Large Language Models (LLM) na **jailbreak**, **prompt injection**, **prompt leaking** i inne zagroÅ¼enia bezpieczeÅ„stwa.

## ğŸ¯ Cel

Framework pozwala pentesterom, red teamers i inÅ¼ynierom bezpieczeÅ„stwa na:

- **Automatyczne testowanie** LLM na podatnoÅ›ci (jailbreak, prompt injection)
- **AnalizÄ™ wynikÃ³w** z detektorem anomalii
- **Generowanie raportÃ³w** (HTML, CSV, JSON)
- **Red teaming** lokalnych modeli
- **OSINT** i reconnaissance na modelach AI
- **Compliance testing** (GDPR, etyka AI)

## ğŸ“‹ Wymagania

- Python 3.8+
- Ollama zainstalowana: https://ollama.com/download
- 12GB+ RAM (lub wiÄ™cej dla wiÄ™kszych modeli)
- Windows 10/11, macOS, Linux (WSL 2 na Windows)

## ğŸš€ Quick Start

### 1. Klon/Pobierz projekt

```bash
git clone https://github.com/yourusername/llm-security-test-framework.git
cd llm-security-test-framework
```

### 2. Zainstaluj zaleÅ¼noÅ›ci

```bash
pip install -r requirements.txt
```

### 3. Zainstaluj model Ollama

```bash
ollama pull gemma3
ollama pull mistral
```

### 4. Uruchom tester

```bash
# Testuj model gemma3 (domyÅ›lnie)
python main.py

# Testuj model mistral
python main.py mistral

# Testuj z GUI
python gui.py
```

## ğŸ“‚ Struktura projektu

```
llm-security-test-framework/
â”œâ”€â”€ main.py                 # CLI - automatyczne testowanie
â”œâ”€â”€ gui.py                  # GUI - interfejs graficzny (Qt6)
â”œâ”€â”€ config.py               # Centralna konfiguracja
â”œâ”€â”€ test_cases.py           # Baza promptÃ³w testowych
â”œâ”€â”€ executor.py             # Komunikacja z Ollama
â”œâ”€â”€ analyzer.py             # Analiza wynikÃ³w i alerty
â”œâ”€â”€ reporter.py             # Generator raportÃ³w
â”œâ”€â”€ requirements.txt        # ZaleÅ¼noÅ›ci
â”œâ”€â”€ .gitignore             # Pliki do ignorowania
â”œâ”€â”€ README.md              # Ten plik
â”œâ”€â”€ outputs/               # Wyniki testÃ³w (CSV, HTML, JSON)
â””â”€â”€ docs/                  # Dokumentacja dodatkowa
```

## ğŸ§ª Kategorie testÃ³w

### Jailbreak
- Podstawowe prompty jailbreak
- Role-playing ataki
- Multi-turnowe jailbreaki
- Hex/encoding jailbreaki
- Zaawansowane techniki

### Prompt Injection
- Podstawowe wstrzykiwanie
- Context injection
- Multi-stage injection
- Ukryta injection

### Prompt Leaking
- Wyciekanie system prompts
- Leak przez kontekst
- WyciÄ…ganie config

### Custom Security Tests
- Testowanie ogÃ³lne
- WraÅ¼liwoÅ›Ä‡ modelu
- OSINT na modelu

### Red Teaming
- Symulacja atakÃ³w
- Scenariusze zagroÅ¼eÅ„
- Bug bounty scenariusze

## ğŸ“Š Wyniki i Raporty

Po uruchomieniu testÃ³w, w folderze `outputs/` znajdziesz:

- **llm_security_tests.csv** - Wyniki w formacie CSV
- **llm_security_test_report.html** - Interaktywny raport HTML
- **llm_security_tests.json** - PeÅ‚ne dane w JSON
- **framework.log** - Logi dziaÅ‚ania

## âš™ï¸ Konfiguracja

Edytuj `config.py` aby zmieniÄ‡:

```python
# Modele do testÃ³w
OLLAMA_MODELS = ["gemma3", "mistral", "llama2"]

# Timeout dla kaÅ¼dego promptu (sekundy)
TEST_CONFIG["timeout"] = 60

# Wymuszanie CPU zamiast GPU
TEST_CONFIG["cpu_mode"] = True

# SÅ‚owa kluczowe do detektowania alertÃ³w
ALERT_KEYWORDS = {...}
```

## ğŸ” SÅ‚owa kluczowe do detektowania

Framework automatycznie szuka:

- **Jailbreak**: jailbreak, bypass, override, ignore, instructions
- **Exploit**: exploit, vulnerability, hack, crack, attack
- **Sensitive**: password, api key, secret, token, credit card
- **Harmful**: malware, virus, ransomware, ddos, bomb
- **Illegal**: illegal, crime, steal, fraud

## ğŸ“ Dodawanie nowych testÃ³w

Edytuj `test_cases.py`:

```python
test_cases = {
    "jailbreak": [
        "TwÃ³j nowy prompt testowy 1",
        "TwÃ³j nowy prompt testowy 2",
    ],
    # Dodaj wiÄ™cej...
}
```

## ğŸ› ï¸ Zaawansowane uÅ¼ycie

### Testowanie wielu modeli

```python
from main import LLMSecurityTester

for model in ["gemma3", "mistral", "llama2"]:
    tester = LLMSecurityTester(model=model)
    tester.run_tests()
    tester.save_results_csv()
```

### Testowanie tylko wybranych kategorii

```python
tester.run_tests(categories=["jailbreak", "prompt_injection"])
```

### Integracja z CI/CD

```yaml
# .github/workflows/security-test.yml
name: LLM Security Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
      - run: pip install -r requirements.txt
      - run: python main.py
```

## âš ï¸ WaÅ¼ne! Etyka i LegalnoÅ›Ä‡

**WHITE HAT ONLY** - Framework przeznaczony WYÅÄ„CZNIE do:

âœ… **Testowania wÅ‚asnych systemÃ³w**
âœ… **Bug bounty (z wyraÅ¼onym zgodÄ…)**
âœ… **Red teamingu w kontrolowanym labie**
âœ… **Edukacji i nauki bezpieczeÅ„stwa AI**

âŒ **NIE** atakuj obcych systemÃ³w bez zgody
âŒ **NIE** uÅ¼ywaj do zÅ‚oÅ›liwych celÃ³w
âŒ **NIE** naruszaj prawa i regulacji

## ğŸ› Znane problemy

### BÅ‚Ä…d: "memory layout cannot be allocated"

```bash
# RozwiÄ…zanie: uruchom model w trybie CPU
python main.py gemma3  # JuÅ¼ ma --cpu w konfiguracji
```

### BÅ‚Ä…d: "Ollama not found"

```bash
# Zainstaluj Ollama z https://ollama.com/download
# Lub uruchom: ollama serve
```

### Model nie odpowiada

```bash
# SprawdÅº czy model jest zainstalowany
ollama list

# Pobierz model
ollama pull mistral
```

## ğŸ“š Dokumentacja

- [Instrukcja instalacji](docs/INSTALL.md)
- [Jak uÅ¼ywaÄ‡](docs/USAGE.md)
- [Architektura](docs/ARCHITECTURE.md)

## ğŸ¤ Kontrybucje

Zapraszamy do wspÃ³Å‚pracy! PodnieÅ› issue lub PR z:

- Nowymi testami
- Poprawieniami
- Raportami o bugach
- DokumentacjÄ…

## ğŸ“„ Licencja

MIT License - Zapoznaj siÄ™ z [LICENSE](LICENSE)

## ğŸ“§ Kontakt

- GitHub Issues: ZgÅ‚oÅ› problem
- Email: your.email@example.com

## ğŸ”— Linki

- [Ollama](https://ollama.com)
- [OWASP Top 10 for LLM](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
- [DEF CON AI Village](https://aivillage.org)
- [HackerOne](https://hackerone.com)

---

**âš ï¸ PamiÄ™taj**: BezpieczeÅ„stwo AI to etyczne zobowiÄ…zanie. UÅ¼ywaj tego narzÄ™dzia odpowiedzialnie!

ğŸ¯ **Happy Testing!**
```
